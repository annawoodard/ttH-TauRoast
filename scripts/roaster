#!/usr/bin/env python
# vim: ts=4:sw=4:et:sta

import argparse
import codecs
import logging
import os
import pickle
import yaml

parser = argparse.ArgumentParser(description='Grill some taus.')
parser.add_argument('config', metavar='config', type=str, nargs=1,
        help='a configuration file to use')
parser.add_argument('-v', '--verbose', action="count", default=0,
        help="increase verbosity")
parser.add_argument('-q', '--quiet', action="count", default=0,
        help="decrease verbosity")
ag = parser.add_argument_group('analysis options')
ag.add_argument('-a', '--analyze', action='store_true', default=False,
        help="analyze datasets")
ag.add_argument('-f', '--fill', action='store_true', default=False,
        help="fill histograms")
ag.add_argument('-p', '--plot', action='store_true', default=False,
        help="save histograms")
ag = parser.add_argument_group('general options')
ag.add_argument('-i', '--input', type=str, default=None,
        help="change input directory")
ag.add_argument('-o', '--output', type=str, default=None,
        help="change output directory")
ag = parser.add_argument_group('debugging and syncronization options')
ag.add_argument('--debug-cuts', action='store_true', default=False,
        help="save event quantites after each cut")

args = parser.parse_args()

if 'LOCALRT' not in os.environ:
    parser.error("need to do a `cmsenv` first")

if not any([args.analyze, args.fill, args.plot]):
    parser.error("need to either analyze, fill, or plot")

# Logging setup
logging.basicConfig(
        datefmt="%Y-%m-%d %H:%M:%S",
        format="%(asctime)s [%(levelname)s] - %(filename)s %(lineno)d: %(message)s")

logging.__dict__['root'].level = (2 + args.quiet - args.verbose) * 10

with open(args.config[0]) as f:
    config = yaml.load(f)

if args.output:
    config['outdir'] = args.output
if args.input:
    config['indir'] = args.input

for k in ('indir', 'outdir', 'ntupledir'):
    if k in config:
        config[k] = os.path.expanduser(os.path.expandvars(config[k]))

datadir = os.path.join(os.environ["LOCALRT"], 'src', 'ttH', 'TauRoast', 'data')
with open(os.path.join(datadir, 'plot.yaml')) as f:
    plotconfig = yaml.load(f)

import ROOT as r

r.gROOT.SetBatch()
r.gErrorIgnoreLevel = 1001
r.gSystem.Load("libttHTauRoast")

from ttH.TauRoast import stylish, useful
from ttH.TauRoast.botany import Forest
from ttH.TauRoast.cutting import StaticCut, Cut, cutflow, normalize
from ttH.TauRoast.plotting import Plot
from ttH.TauRoast.processing import Process
from ttH.TauRoast.variation import setup

useful.setup(config['channel'], config['generator'])
useful.load_python(config.get('sync', False))
stylish.setup()

if not os.path.exists(config["outdir"]):
    os.makedirs(config["outdir"])

if 'mva' in config:
    cfg = config['mva']
    setup(config['outdir'], cfg['variables'])

if args.analyze:
    counts = []
    cuts = [
            Cut("Ntuple analyzed", "true")
    ]
    weights = []

    for cfg in config["cuts"]:
        cuts.append(Cut(*cfg.items()[0]))

    for weight in config["weights"]:
        weights.append(StaticCut(weight))

    fn = os.path.join(config["outdir"], "ntuple.root")
    if os.path.exists(fn):
        os.unlink(fn)

    processed = set()
    for proc in sum(map(Process.expand, config['plot']), []):
        if proc in processed:
            continue
        processed.add(proc)
        local_cuts = list(cuts)
        for cfg in proc.additional_cuts:
            local_cuts.insert(0, Cut(*cfg))

        proc.analyze(fn, counts, local_cuts, weights, config["systematics"], config['ntupledir'], config.get('event limit', -1), args.debug_cuts)

    cuts = counts + cuts + weights
    normalize(cuts, config["lumi"], config.get("event limit"))
    try:
        cutflow(cuts, config["plot"])
    except UnicodeEncodeError:
        pass

    with codecs.open(os.path.join(config["outdir"], "cuts.txt"), "w", encoding="utf8") as fd:
        cutflow(cuts, config["plot"], f=fd)
    with codecs.open(os.path.join(config["outdir"], "cuts_relative.txt"), "w", encoding="utf8") as fd:
        cutflow(cuts, config["plot"], f=fd, relative=True)
    with codecs.open(os.path.join(config["outdir"], "cuts_weighed.txt"), "w", encoding="utf8") as fd:
        cutflow(cuts, config["plot"], f=fd, weighed=True)

    fn = os.path.join(config["outdir"], "cutflow.pkl")
    with open(fn, 'wb') as f:
        pickle.dump(cuts, f)
elif args.fill:
    fn = os.path.join(config.get("indir", config["outdir"]), "cutflow.pkl")
    with open(fn, 'rb') as f:
        cuts = pickle.load(f)[:-2]
    normalize(cuts, config["lumi"], config.get("event limit"))
    try:
        cutflow(cuts, config["plot"])
    except UnicodeEncodeError:
        pass

    with codecs.open(os.path.join(config["outdir"], "cuts.txt"), "w", encoding="utf8") as fd:
        cutflow(cuts, config["plot"], f=fd)
    with codecs.open(os.path.join(config["outdir"], "cuts_relative.txt"), "w", encoding="utf8") as fd:
        cutflow(cuts, config["plot"], f=fd, relative=True)
    with codecs.open(os.path.join(config["outdir"], "cuts_weighed.txt"), "w", encoding="utf8") as fd:
        cutflow(cuts, config["plot"], f=fd, weighed=True)

categories = []
definitions = []
for cfg in config.get("categories", [{'inclusive': None}]):
    category, definition = cfg.items()[0]
    categories.append(category)
    definitions.append(definition)

if args.fill:
    fn = os.path.join(config.get("indir", config["outdir"]), "ntuple.root")
    forest = Forest(fn)

    for category, definition in zip(categories, definitions):
        Plot.reset()

        processed = set()
        for proc in sum(map(Process.expand, config['plot']), []):
            if proc in processed:
                continue
            processed.add(proc)
            for p in Plot.plots():
                p.fill(proc, config["weights"], definition)

        fn = os.path.join(config["outdir"], "plots.root")
        f = r.TFile(fn, "UPDATE")

        if not f.IsOpen():
            raise IOError("Can't read file '{0}'".format(fn))

        for p in Plot.plots():
            p.write(f, cuts, category, fmt=config["histformat"])

        f.Write()
        f.Close()

        fn = os.path.join(config["outdir"], "limits.root")
        f = r.TFile(fn, "UPDATE")

        if not f.IsOpen():
            raise IOError("Can't read file '{0}'".format(fn))

        for p in Plot.plots():
            p.write(f, cuts, category, procs=config["limits"], fmt=config["histformat"])

        timing = sorted(Plot.plots(), key=lambda p: p._time)
        for p in timing[:10] + timing[-10:]:
            logging.debug("plot filling time for {0}: {1}".format(p, p._time))

        f.Write()
        f.Close()
    del forest

if args.fill or args.plot:
    counts = []

    fn = os.path.join(config.get("indir", config["outdir"]), "plots.root")
    f = r.TFile(fn, "READ")

    if not f.IsOpen():
        raise IOError("Can't read file '{0}'".format(fn))

    for proc in config['plot']:
        count = StaticCut(proc)
        for cat in categories:
            count[cat] = Plot.get_event_count(f, proc, cat, config['histformat'])
        counts.append(count)

    try:
        useful.print_cuts(counts, categories)
    except UnicodeEncodeError:
        pass

    with codecs.open(os.path.join(config["outdir"], "categories.txt"), "w", encoding="utf8") as fd:
        useful.print_cuts(counts, categories, f=fd)

if args.plot:
    for category in categories:
        Plot.reset()

        processes = sum(map(Process.expand, config['plot']), [])
        fn = os.path.join(config.get("indir", config["outdir"]), "plots.root")
        f = r.TFile(fn, "READ")

        if not f.IsOpen():
            raise IOError("Can't read file '{0}'".format(fn))

        for p in Plot.plots():
            p.read(f, category, processes, fmt=config["histformat"])
            p.save(plotconfig, os.path.join(config["outdir"], category))

        f.Close()
