# vim: set sw=4 sta et :

analysis:
    channel: ttl

    max events: -1

    final mva:
        methods:
            BDTG: "!H:!V:NTrees=1000:BoostType=Grad:Shrinkage=0.10:UseBaggedGrad:GradBaggingFraction=0.5:nCuts=20:NNodesMax=5"
        signal: TTHTauTau_125_real
        background: [TTbar_Hadronic, TTbar_SemiLept, TTbar_FullLept]
        variables:
          - [T1_Pt, F]
          - [T1_Eta, F, True]
          - [T2_Pt, F]
          - [T1_DecayMode, I]
          - [T2_DecayMode, I]
          - [T1_IsolationMVA2Raw, F]
          - [T2_IsolationMVA2Raw, F]
          - [T1L_DeltaR, F]
          - [CleanLJ_Pt, F]
          - [DitauVisibleMass, F]

    process:
      - Collisions
      - TTbar
      - EWK
      - SingleTop
      - ttWZ
      - TTHTauTau_125_real
      #  - TTH_110
      #  - TTH_115
      #  - TTH_120
      - TTH_125
      #  - TTH_130
      #  - TTH_135
      #  - TTH_140

    plot:
      - Collisions
      - TTbar
      - EWK
      - SingleTop
      - ttWZ
      - TTH_125

display:
    legend: False
    legend columns: 3
    signal scale factor: 100

physics:
    lumi: 19400
    flags:
      - [topPt, nominal]
      - [lepton, nominal]
      - [PUcorr, nominal]
      - [CSVeventWeight, nominal]
      - [brSF, nominal]
    cuts:
      # reality
      - T1_MatchAbsId = 15
      - T2_MatchAbsId = 15
      - T1_ParentAbsId = 25
      - T2_ParentAbsId = 25
      # tops
      - 1 ≤ J_NumCleanCSVM ≤ 2
      - J_NumCleanInclusive ≥ 2
      # lepton
      - NumTightLeptons = 1
      - NumExLooseLeptons = 0
      - L_Pt ≥ 30
      # taus
      - TT_DeltaR ≥ 0.5
      # topological
      - T1L_DeltaR ≥ 0.25
      - T2L_DeltaR ≥ 0.25
      # optimization
      - T1_NumProngs = 1
      - T2_NumProngs = 1
      - T1_IsolationIndex3Hits ≥ 1
      # topological
      - TT_ChargeProduct = -1
    pair selection: pt
    systematics:
        eTauFake: 1.05
        jetTauFake: 1.2
        tauIdEff: 1.06

paths:
    # root path, referenced by {root}
    root: /afs/crc.nd.edu/user/m/mwolf3/www/ttH/v64/ttl
    # for analyzed processes
    input: "{root}/roast_processed.root"
    # {s} is replaced with systematic shifts
    systematics input: "{root}_{s}/roast_filled.root"
    # for processes with filled histograms
    output: "{root}/roast_filled.root"
    # for further processing with `mk_datcard` and `combine`
    limit output: "{root}/roast_limit.root"
    mva output: "{root}/{m}"
    # allowed wildcards: {t} = type (pdf, png); {d} = directory; {n} =
    # name; {m} = mode (_log)
    stack format: "{root}/{t}/{d}/{n}{p}{m}.{t}"
    ntuples: "/hadoop/users/matze/ttH/v64/2012/ttl_{p}/*_ntuple.root"

processes: !include processes.yaml
histograms: !include histograms*.yaml
